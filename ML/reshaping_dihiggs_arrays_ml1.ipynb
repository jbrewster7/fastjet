{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464c94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fastjet\n",
    "from coffea.nanoevents import NanoEventsFactory, EDM4HEPSchema\n",
    "import dask_awkward as dak\n",
    "import hist.dask as hda\n",
    "import uproot\n",
    "from ak_tools import ak_equals\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cf4bbb-d800-407e-b8d0-5e27555d3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3' # set GPU\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5cb07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cppyy_backend/loader.py:139: UserWarning: No precompiled header available (/usr/local/lib/python3.8/dist-packages/cppyy_backend/etc not writable, set CLING_STANDARD_PCH); this may impact performance.\n",
      "  warnings.warn('No precompiled header available (%s); this may impact performance.' % msg)\n",
      "/home/jbrewster/.local/lib/python3.8/site-packages/numba/core/cpu.py:99: UserWarning: Numba extension module 'cppyy.numba_ext' failed to load due to 'ModuleNotFoundError(No module named 'llvmlite.llvmpy')'.\n",
      "  numba.core.entrypoints.init_all()\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:63: UserWarning: Skipping PARAMETERS as it is it cannot be interpreted by Uproot\n",
      "  warnings.warn(\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:45: UserWarning: Skipping _intMap as it is not interpretable by Uproot\n",
      "  warnings.warn(\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _intMap.first as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _intMap.second as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:45: UserWarning: Skipping _floatMap as it is not interpretable by Uproot\n",
      "  warnings.warn(\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _floatMap.first as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _floatMap.second as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:45: UserWarning: Skipping _stringMap as it is not interpretable by Uproot\n",
      "  warnings.warn(\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _stringMap.first as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _stringMap.second as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:45: UserWarning: Skipping _doubleMap as it is not interpretable by Uproot\n",
      "  warnings.warn(\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _doubleMap.first as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n",
      "/home/jbrewster/projects/coffea/src/coffea/nanoevents/factory.py:52: UserWarning: Skipping _doubleMap.second as it is not interpretable by Uproot\n",
      "  warnings.warn(f\"Skipping {branch.name} as it is not interpretable by Uproot\")\n"
     ]
    }
   ],
   "source": [
    "events = NanoEventsFactory.from_root( \n",
    "    {\"/data/linear/Pe2e2hh.eL.pR.n000.d_dstm_15806_0_patched_collections_edm4hep_test_Jim.root\"\n",
    "    :\"events\"},\n",
    "    schemaclass=EDM4HEPSchema,\n",
    "    permit_dask=True,\n",
    "    metadata = {'b_field':5},\n",
    ").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51a5311-3313-497f-8bd2-54ee74dfd216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up needed arrays\n",
    "file = uproot.open(\"/data/linear/Pe2e2hh.eL.pR.n000.d_dstm_15806_0_patched_collections_edm4hep_test_Jim.root\")\n",
    "\n",
    "evs = file['events']\n",
    "uproot_parinds = (evs[f'_MCParticlesSkimmed_parents/_MCParticlesSkimmed_parents.index']).array()\n",
    "uproot_daughinds = (evs[f'_MCParticlesSkimmed_daughters/_MCParticlesSkimmed_daughters.index']).array() \n",
    "\n",
    "pshape = (events.MCParticlesSkimmed.parents_end - events.MCParticlesSkimmed.parents_begin).compute()\n",
    "par_inds = ak.unflatten(uproot_parinds,ak.flatten(pshape),axis=1)\n",
    "\n",
    "dshape = (events.MCParticlesSkimmed.daughters_end - events.MCParticlesSkimmed.daughters_begin).compute()\n",
    "daugh_inds = ak.unflatten(uproot_daughinds,ak.flatten(dshape),axis=1)\n",
    "\n",
    "pdgids = events.MCParticlesSkimmed.pdgId.compute()\n",
    "\n",
    "\n",
    "arr_reco = events.RecoMCTruthLink.reco_index.compute()\n",
    "arr_mc = events.RecoMCTruthLink.mc_index.compute()\n",
    "sort_reco = arr_reco[ak.argsort(arr_reco)]\n",
    "sort_mc = arr_mc[ak.argsort(arr_reco)]\n",
    "\n",
    "proper_indices = ak.unflatten(sort_mc,ak.flatten(ak.run_lengths(sort_reco),axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e19cf6c-d5df-4449-a497-c3d0706801d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfos = events.PandoraPFOs.compute()\n",
    "mc = events.MCParticlesSkimmed.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111dd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_truehiggs(reco_particles,mc_particles,true_higgs,reco_mc_index,jet_constits_index,condition='pR',pcrit=(50,5)):\n",
    "    '''\n",
    "    compares jet constituents to true higgs products \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    reco_particles :: array\n",
    "        array with all the reco particles\n",
    "    \n",
    "    mc_particles :: array\n",
    "        array with all the mc particles\n",
    "    \n",
    "    true_higgs :: array \n",
    "        array containing the mc indices of all the children of the higgs in each event \n",
    "    \n",
    "    reco_mc_index :: array \n",
    "        array containing a list of mc indices for each reco index\n",
    "    \n",
    "    jet_constits_index :: array \n",
    "        indices of the pfos contained in the jets in the reco particle array\n",
    "    \n",
    "    condition :: str (optional)\n",
    "        'pR' - the link with the closest momentum match is from the true higgs, to within 50% of the reco momentum \n",
    "               or 5 GeV, otherwise the closest \\Delta R between the two closest momentum matches\n",
    "               (criteria can be changed with pcrit)\n",
    "        'p' - the link with the closest momentum match is from the true higgs\n",
    "        'any' - any of one of the links from reco particles to mc particles is from the true higgs \n",
    "        'all' - all of the links from reco particles to mc particles is from the true higgs \n",
    "    \n",
    "    pcrit :: tuple (optional)\n",
    "        tuple defining the criteria for using momentum when condition = 'pR' as \n",
    "        (percent,absolute) FINISH DESCRIPTION\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    \n",
    "    '''\n",
    "    matrix = False\n",
    "    \n",
    "    # throw error if any of the things are not the right lengths\n",
    "    if not (len(reco_particles) == len(mc_particles) and len(mc_particles) == len(true_higgs) and len(true_higgs) == len(reco_mc_index) and len(reco_mc_index) == len(jet_constits_index)):\n",
    "        raise ValueError('first 5 arrays must have the same number of events')\n",
    "    \n",
    "    jet_mcindices = reco_mc_index[jet_constits_index]\n",
    "    jet_con_in_higgs = []\n",
    "    \n",
    "    if condition == 'pR':\n",
    "        # complete (right now this is the same as 'p')\n",
    "        matched_gen = ak.unflatten(mc_particles[ak.flatten(reco_mc_index,axis=2)],ak.flatten(ak.num(reco_mc_index,axis=2)),axis=1)\n",
    "        \n",
    "        mc_reco_cartesian = ak.argcartesian({'mc':matched_gen.p,'reco':ak.singletons(reco_particles.p,axis=1)},axis=2)\n",
    "        mc_p_argmin = ak.singletons(ak.argmin(abs(matched_gen.p[mc_reco_cartesian['mc']] - ak.singletons(reco_particles.p,axis=1)[mc_reco_cartesian['reco']]),axis=2),axis=1)\n",
    "        \n",
    "        all_jet_inds = ak.flatten(reco_mc_index[mc_p_argmin],axis=2)[jet_constits_index]\n",
    "        \n",
    "        for n in range(len(all_jet_inds)):\n",
    "            jet_con_in_higgs.append(np.isin(all_jet_inds[n],true_higgs[n]))\n",
    "\n",
    "        jet_con_in_higgs = ak.Array(jet_con_in_higgs)\n",
    "        \n",
    "    elif condition == 'any' or condition == 'all':\n",
    "        all_jet_inds = ak.flatten(jet_mcindices,axis=2)\n",
    "        \n",
    "        jet_con_in_higgs = []\n",
    "\n",
    "        for n in range(len(all_jet_inds)):\n",
    "            jet_con_in_higgs.append(np.isin(all_jet_inds[n],true_higgs[n]))\n",
    "\n",
    "        jet_con_in_higgs = ak.Array(jet_con_in_higgs)\n",
    "        \n",
    "        if condition == 'any':\n",
    "            jet_con_in_higgs = ak.any(ak.unflatten(jet_con_in_higgs,ak.flatten(ak.num(jet_mcindices,axis=2)),axis=1),axis=2)\n",
    "        else:\n",
    "            jet_con_in_higgs = ak.all(ak.unflatten(jet_con_in_higgs,ak.flatten(ak.num(jet_mcindices,axis=2)),axis=1),axis=2)\n",
    "        \n",
    "    elif condition == 'p':\n",
    "        matched_gen = ak.unflatten(mc_particles[ak.flatten(reco_mc_index,axis=2)],ak.flatten(ak.num(reco_mc_index,axis=2)),axis=1)\n",
    "        \n",
    "        mc_reco_cartesian = ak.argcartesian({'mc':matched_gen.p,'reco':ak.singletons(reco_particles.p,axis=1)},axis=2)\n",
    "        mc_p_argmin = ak.singletons(ak.argmin(abs(matched_gen.p[mc_reco_cartesian['mc']] - ak.singletons(reco_particles.p,axis=1)[mc_reco_cartesian['reco']]),axis=2),axis=1)\n",
    "        \n",
    "        all_jet_inds = ak.flatten(reco_mc_index[mc_p_argmin],axis=2)[jet_constits_index]\n",
    "                \n",
    "        if matrix:\n",
    "            jet_con_in_higgs = ak_equals(all_jet_inds,true_higgs)\n",
    "        else:\n",
    "            for n in range(len(all_jet_inds)):\n",
    "                jet_con_in_higgs.append(np.isin(all_jet_inds[n],true_higgs[n]))\n",
    "\n",
    "            jet_con_in_higgs = ak.Array(jet_con_in_higgs)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('condition must be \\'p\\', \\'any\\', or \\'all\\'')\n",
    "    \n",
    "    \n",
    "    return jet_con_in_higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13006f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '/fast_scratch_1/jbrewster/dihiggs_ML/storing_misc/'\n",
    "\n",
    "higgs_children_0 = pickle.load(open(pickle_path + 'higgs_children_0.pickle','rb'))\n",
    "higgs_children_1 = pickle.load(open(pickle_path + 'higgs_children_1.pickle','rb'))\n",
    "higgs_daughter_tree_arr_0 = pickle.load(open(pickle_path + 'higgs_daughter_tree_arr_0.pickle','rb'))\n",
    "higgs_daughter_tree_arr_1 = pickle.load(open(pickle_path + 'higgs_daughter_tree_arr_1.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bc709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mupair = dak.combinations(events.PandoraPFOs[abs(events.PandoraPFOs.pdgId) == 13], 2, fields=[\"mu1\", \"mu2\"])\n",
    "pairmass = (mupair.mu1 + mupair.mu2).mass\n",
    "muonsevent = dak.any(\n",
    "    (pairmass > 80)\n",
    "    & (pairmass < 100)\n",
    "    & (mupair.mu1.charge == -mupair.mu2.charge),\n",
    "    axis=1,\n",
    ")\n",
    "muonsevent_c = muonsevent.compute()\n",
    "\n",
    "jetdef = fastjet.JetDefinition(fastjet.kt_algorithm,1)\n",
    "\n",
    "pfopair = dak.argcombinations(events.PandoraPFOs, 2, fields=[\"p1\", \"p2\"])\n",
    "\n",
    "all_muons_mask = (abs(events.PandoraPFOs[pfopair.p1].pdgId) == 13) & (abs(events.PandoraPFOs[pfopair.p2].pdgId) == 13)\n",
    "\n",
    "invmass = (events.PandoraPFOs[pfopair.p1][all_muons_mask] + events.PandoraPFOs[pfopair.p2][all_muons_mask]).mass\n",
    "\n",
    "inds = dak.singletons(dak.argmin(abs(invmass - 91.2), axis=1))\n",
    "\n",
    "\n",
    "mu1ind = pfopair.p1[all_muons_mask][inds]\n",
    "mu2ind = pfopair.p2[all_muons_mask][inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = mu1ind[muonsevent].compute()\n",
    "m2 = mu2ind[muonsevent].compute()\n",
    "\n",
    "p = events.PandoraPFOs[muonsevent].compute()\n",
    "\n",
    "local_inds = ak.local_index(p)\n",
    "total_mask = ((ak_equals(local_inds, m1)) | (ak_equals(local_inds, m2))) != True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfos_h0 = jet_truehiggs(pfos[muonsevent_c][total_mask],\n",
    "                        mc[muonsevent_c],\n",
    "                        higgs_children_0[muonsevent_c],\n",
    "                        proper_indices[muonsevent_c][total_mask],\n",
    "                        ak.local_index(pfos[muonsevent_c][total_mask]),\n",
    "                        'p')\n",
    "\n",
    "pfos_h1 = jet_truehiggs(pfos[muonsevent_c][total_mask],\n",
    "                        mc[muonsevent_c],\n",
    "                        higgs_children_1[muonsevent_c],\n",
    "                        proper_indices[muonsevent_c][total_mask],\n",
    "                        ak.local_index(pfos[muonsevent_c][total_mask]),\n",
    "                        'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ae8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making truth array \n",
    "true_arr = ak.fill_none(\n",
    "    ak.mask(\n",
    "        ak.fill_none(\n",
    "            ak.mask(\n",
    "                ak.fill_none(\n",
    "                    ak.mask(pfos_h0,pfos_h0 != True),ak.Array([1,0,0])),\n",
    "                pfos_h1 != True\n",
    "            ),\n",
    "            ak.Array([0,1,0])\n",
    "        ),\n",
    "        pfos_h0 | pfos_h1,\n",
    "    ),\n",
    "    ak.Array([0,0,1]),\n",
    ")\n",
    "\n",
    "padded_true_arr = ak.fill_none(ak.pad_none(true_arr,np.max(ak.num(true_arr,axis=1))),ak.Array([-1,-1,-1]))\n",
    "\n",
    "padded_true_np = np.array(ak.unflatten(ak.unflatten(ak.ravel(padded_true_arr),ak.num(padded_true_arr)*3),3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening pfo dict into tuples \n",
    "# possibly tell it the data type here \n",
    "\n",
    "masked_pfos = pfos[muonsevent_c][total_mask]\n",
    "\n",
    "# masked_pfos_tupled = ak.zip([masked_pfos.x,masked_pfos.y,masked_pfos.z,masked_pfos.E])\n",
    "\n",
    "# masked_pfos_tupled = ak.zip([np.log(masked_pfos.p)*masked_pfos.x/masked_pfos.p,\n",
    "#                              np.log(masked_pfos.p)*masked_pfos.y/masked_pfos.p,\n",
    "#                              np.log(masked_pfos.p)*masked_pfos.z/masked_pfos.p,\n",
    "#                              np.log(masked_pfos.E)])\n",
    "\n",
    "masked_pfos_tupled = ak.zip([np.log(masked_pfos.p)*masked_pfos.x/masked_pfos.p,\n",
    "                             np.log(masked_pfos.p)*masked_pfos.y/masked_pfos.p,\n",
    "                             np.log(masked_pfos.p)*masked_pfos.z/masked_pfos.p,\n",
    "                             (np.log(masked_pfos.E)-np.mean(np.log(masked_pfos.E)))/np.max(np.log(masked_pfos.E)-np.mean(np.log(masked_pfos.E)))])\n",
    "\n",
    "# masked_pfos_tupled = ak.zip([masked_pfos.x,masked_pfos.y,masked_pfos.z,np.log(masked_pfos.E)])\n",
    "\n",
    "padded_pfo_arr = ak.fill_none(ak.pad_none(masked_pfos_tupled,np.max(ak.num(pfos,axis=1))),ak.Array([-1,-1,-1,-1]))\n",
    "\n",
    "padded_pfo_np = np.array(ak.unflatten(ak.unflatten(ak.ravel(padded_pfo_arr),ak.num(padded_pfo_arr)*4),4,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880eabd-a215-4be9-8cb7-66533ac8c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.log(masked_pfos.p)*masked_pfos.x/masked_pfos.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "177437a0-3e58-44a2-8214-49751a04df9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5207872"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.log(masked_pfos.E)-np.mean(np.log(masked_pfos.E)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "babb2430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_top = int(len(padded_pfo_arr)*0.7)\n",
    "val_top = int(train_top + len(padded_pfo_arr)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c116f78e-fd77-43b9-b197-ba1524739f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83722"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c0939c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = padded_pfo_np[:train_top]\n",
    "train_truth = padded_true_np[:train_top]\n",
    "\n",
    "test_data = padded_pfo_np[train_top:val_top]\n",
    "test_truth = padded_true_np[train_top:val_top]\n",
    "\n",
    "val_data = padded_pfo_np[val_top:]\n",
    "val_truth = padded_true_np[val_top:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32f580e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/fast_scratch_1/jbrewster/dihiggs_ML/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dd4e002-50f2-447a-ad03-d71a9098c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_points_file = data_path + 'max_points.txt'\n",
    "file = open(max_points_file, 'w')\n",
    "file.write(str(ak.num(train_data)[0]))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c940388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with X and Y labels\n",
    "# np.savez(data_path + 'train/dihiggs',X=train_data,Y=train_truth)\n",
    "# np.savez(data_path + 'test/dihiggs',X=test_data,Y=test_truth)\n",
    "# np.savez(data_path + 'val/dihiggs',X=val_data,Y=val_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76ff7cde-ea58-40cc-992c-176e035fc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(int(np.ceil(len(train_data)/6000))):\n",
    "    top = (n+1)*6000\n",
    "    if top < len(train_data):\n",
    "        np.savez(data_path + 'train/dihiggs' + str(n),X=train_data[n*6000:top],Y=train_truth[n*6000:top])\n",
    "    else:\n",
    "        np.savez(data_path + 'train/dihiggs' + str(n),X=train_data[top:],Y=train_truth[top:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f20bce3c-2493-4bd6-864b-b805206a8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(int(np.ceil(len(test_data)/6000))):\n",
    "    top = (n+1)*6000\n",
    "    if top < len(test_data):\n",
    "        np.savez(data_path + 'test/dihiggs' + str(n),X=test_data[n*6000:top],Y=test_truth[n*6000:top])\n",
    "    else:\n",
    "        np.savez(data_path + 'test/dihiggs' + str(n),X=test_data[top:],Y=test_truth[top:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e555f11-7e8c-4e43-af5a-8dff6906c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(int(np.ceil(len(val_data)/6000))):\n",
    "    top = (n+1)*6000\n",
    "    if top < len(val_data):\n",
    "        np.savez(data_path + 'val/dihiggs' + str(n),X=val_data[n*6000:top],Y=val_truth[n*6000:top])\n",
    "    else:\n",
    "        np.savez(data_path + 'val/dihiggs' + str(n),X=val_data[top:],Y=val_truth[top:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
